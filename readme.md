# College RAG Chatbot - Code Workflow

## ğŸ“‹ Overview
A Retrieval-Augmented Generation (RAG) chatbot that answers questions about colleges using a CSV database, vector search, and AI text generation.

---

## ğŸ”§ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. GREETING CHECK              â”‚
â”‚  Is it a greeting/common phrase?â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Yes           â”‚ No
         â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Return â”‚    â”‚ 2. EMBEDDING â”‚
    â”‚Greetingâ”‚    â”‚ Convert queryâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ to vector    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                  â”‚
        â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3a. SEARCH DB    â”‚            â”‚ 3b. SEARCH MEMORYâ”‚
â”‚ Find similar     â”‚            â”‚ Find similar Q/A â”‚
â”‚ college records  â”‚            â”‚ from past chats  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 4. FILTER & MERGE  â”‚
         â”‚ Keep only relevant â”‚
         â”‚ results (threshold)â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ No                  â”‚ Yes
         â–¼                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Return     â”‚    â”‚ 5. BUILD PROMPTâ”‚
    â”‚"No Data"   â”‚    â”‚ Context + Queryâ”‚
    â”‚ Message    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 6. GENERATE ANSWERâ”‚
                    â”‚ AI Model produces â”‚
                    â”‚ response text     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 7. SAVE TO MEMORY â”‚
                    â”‚ Store Q/A for     â”‚
                    â”‚ future retrieval  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 8. RETURN ANSWER  â”‚
                    â”‚ Display to user   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Step-by-Step Workflow

### **INITIALIZATION PHASE** (Runs once at startup)

#### Step 1: Load Configuration
- Set file paths (CSV, FAISS indexes, logs)
- Configure models (embedding, generation)
- Set parameters (top-k results, batch size, thresholds)

#### Step 2: Setup Logging
- Create file logger â†’ `college_rag.log`
- Create console logger â†’ Terminal output
- Log timestamps and events

#### Step 3: Build/Load Database
```
IF processed CSV + FAISS index exist:
    â†’ Load from disk (fast)
ELSE:
    â†’ Read colleges.csv
    â†’ Combine all columns into "combined" text
    â†’ Generate embeddings (batched for speed)
    â†’ Normalize vectors (for cosine similarity)
    â†’ Build FAISS index (IndexFlatIP)
    â†’ Save to disk for future use
```

#### Step 4: Initialize Memory System
```
IF memory.jsonl exists:
    â†’ Load past Q/A entries
IF memory.index exists:
    â†’ Load memory FAISS index
ELSE:
    â†’ Create empty memory (builds on first query)
```

#### Step 5: Load AI Models
- **Embedding Model**: `intfloat/e5-base-v2` (converts text â†’ vectors)
- **Generation Model**: `TinyLlama-1.1B-Chat` (generates answers)

---

### **QUERY PROCESSING PHASE** (Runs for each user question)

#### Step 6: Receive User Query
```python
User: "What are the top engineering colleges in Mumbai?"
```

#### Step 7: Check for Greetings
```
IF query matches greeting patterns:
    â†’ Return pre-defined friendly response
    â†’ SKIP to Step 14 (no RAG needed)
```

**Greeting Examples:**
- "hi" â†’ "Hello! How can I assist you?"
- "thank you" â†’ "You're very welcome! ğŸ˜Š"
- "bye" â†’ "Goodbye! ğŸ‘‹ Keep learning."

#### Step 8: Embed Query
```python
query_text = "query: What are the top engineering colleges in Mumbai?"
query_vector = embedding_service.embed_texts([query_text])
# Result: [0.123, -0.456, 0.789, ...] (384-dim vector)
```

#### Step 9: Search Database (FAISS)
```
1. Search DB index with query vector
2. Get top-k results (default: 3)
3. Each result has:
   - Score (similarity: 0.0 to 1.0)
   - Index (row in CSV)
   
Example:
  [Score: 0.85] â†’ Row 42: "IIT Bombay | Mumbai | Engineering | ..."
  [Score: 0.72] â†’ Row 108: "VJTI | Mumbai | Engineering | ..."
  [Score: 0.68] â†’ Row 215: "SPIT | Mumbai | Engineering | ..."
```

#### Step 10: Search Memory (Recent Q/A)
```
1. Load past Q/A entries from memory.jsonl
2. Rebuild memory FAISS index (small, so fast)
3. Search memory with query vector
4. Get top-k_mem results (default: 3)

Example:
  [Score: 0.91] â†’ "Q: Best engineering colleges? A: IIT Bombay ranks..."
  [Score: 0.76] â†’ "Q: Mumbai colleges? A: VJTI is highly regarded..."
```

#### Step 11: Filter Results by Threshold
```
SIMILARITY_THRESHOLD = 0.2 (configurable)

For each result (DB + Memory):
    IF score >= 0.2:
        â†’ Keep it
    ELSE:
        â†’ Discard (not relevant enough)
```

#### Step 12: Build Context Block
```
1. Merge DB + Memory results
2. Sort by score (highest first)
3. Truncate texts to avoid overflow
4. Create formatted context:

Context:
---
[score:0.91] Q: Best engineering colleges? A: IIT Bombay ranks #1...
---
[score:0.85] IIT Bombay | Mumbai | Engineering | Fees: 2L/year...
---
[score:0.76] Q: Mumbai colleges? A: VJTI is highly regarded...
---
```

#### Step 13: Generate Answer

**IF NO CONTEXT FOUND:**
```python
return "I couldn't find any relevant information in my database. 
        Please provide more details (college name/program/location)."
```

**IF CONTEXT FOUND:**
```
1. Build prompt:
   - System instruction: "You are CollegeBot, concise and factual"
   - Context block (from Step 12)
   - User question
   - Rules: "Answer only from context, don't hallucinate"

2. Send to AI generation model
3. Retry up to 3 times if fails
4. Extract answer from model output
5. Clean up formatting
```

**Example Prompt:**
```
You are CollegeBot â€” concise, professional, and factual.

Context:
[score:0.85] IIT Bombay | Mumbai | Engineering | Fees: 2L/year...
[score:0.72] VJTI | Mumbai | Engineering | Fees: 80K/year...

User Question: What are the top engineering colleges in Mumbai?

Instructions:
- Answer only based on the provided context
- Be concise and helpful
- Don't hallucinate

Answer:
```

**Model Output:**
```
Based on the data, the top engineering colleges in Mumbai include:
1. IIT Bombay - Premier institution with â‚¹2L/year fees
2. VJTI - Highly regarded with â‚¹80K/year fees
```

#### Step 14: Save to Memory
```python
memory_entry = {
    "id": 1698765432000,
    "question": "What are the top engineering colleges in Mumbai?",
    "answer": "Based on the data, the top engineering colleges...",
    "timestamp": "2025-10-30T10:30:45Z"
}

â†’ Append to memory.jsonl
â†’ Keep only last 300 entries (rolling window)
```

#### Step 15: Return Answer to User
```
ğŸ¯ Answer:
------------------------------------------------------------
Based on the data, the top engineering colleges in Mumbai include:
1. IIT Bombay - Premier institution with â‚¹2L/year fees
2. VJTI - Highly regarded with â‚¹80K/year fees
------------------------------------------------------------
```

---

## ğŸ—‚ï¸ Data Flow Summary

```
CSV File (colleges.csv)
    â†“ [Read & Process]
Preprocessed CSV (colleges_processed.csv)
    â†“ [Generate Embeddings]
FAISS Index (colleges.index) â†’ Fast Vector Search
    â†“
User Query â†’ Embedding â†’ Search â†’ Context
    â†“
AI Model â†’ Generate Answer
    â†“
memory.jsonl (Q/A History) â†’ Future Retrieval
```

---

## ğŸ› ï¸ Key Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Embeddings** | SentenceTransformer (e5-base-v2) | Convert text â†’ vectors |
| **Vector Search** | FAISS (IndexFlatIP) | Fast similarity search |
| **Generation** | TinyLlama-1.1B-Chat | Generate natural answers |
| **Database** | Pandas + CSV | Store college data |
| **Memory** | JSONL + FAISS | Store past Q/A |
| **Logging** | Python logging | Track events |

---

## ğŸ“Š Performance Features

1. **Batched Embeddings**: Process 64 texts at once (faster than one-by-one)
2. **Normalized Vectors**: Use cosine similarity via inner product (efficient)
3. **Persistent Indexes**: Load pre-built FAISS indexes (skip re-computation)
4. **Threshold Filtering**: Discard low-quality results (cleaner answers)
5. **Memory System**: Learn from past conversations (improves over time)
6. **Retry Logic**: Handle generation failures gracefully

---

## ğŸ¯ Usage Example

```bash
$ python college_rag_chatbot.py

ğŸ“ College RAG Chatbot â€” type 'exit' or 'quit' to stop.

You: hi
ğŸ¯ Answer: Hello! How can I assist you with college or course info today?

You: What are the fees for IIT Bombay?
[Searches DB â†’ Finds IIT Bombay record â†’ Generates answer]
ğŸ¯ Answer: IIT Bombay's tuition fees are approximately â‚¹2 lakh per year...

You: thank you
ğŸ¯ Answer: You're very welcome! ğŸ˜Š

You: exit
ğŸ‘‹ Goodbye!
```

---

## ğŸ“ Configuration Guide

### Adjust Performance
```python
TOP_K = 3              # More results = better context (slower)
BATCH_SIZE = 64        # Larger = faster (needs more memory)
SIMILARITY_THRESHOLD = 0.2  # Higher = stricter (fewer results)
```

### Change Models
```python
EMBED_MODEL_NAME = "intfloat/e5-base-v2"  # Swap for different embeddings
GEN_MODEL = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"  # Use larger LLMs
```

### Memory Settings
```python
MEMORY_MAX_ENTRIES = 300  # Keep last N Q/A pairs
TOP_K_MEM = 3            # How many memory results to retrieve
```

---

## ğŸ› Error Handling

1. **No Data Found**: Returns polite "no information" message
2. **Generation Failure**: Retries 3 times, then shows error message
3. **Index Missing**: Rebuilds from CSV automatically
4. **Memory Corruption**: Rebuilds memory index on next query

---

## ğŸ“‚ File Structure

```
project/
â”œâ”€â”€ college_rag_chatbot.py      # Main code
â”œâ”€â”€ colleges.csv                # Input data
â”œâ”€â”€ colleges_processed.csv      # Preprocessed data
â”œâ”€â”€ colleges.index              # DB FAISS index
â”œâ”€â”€ memory.jsonl                # Q/A history
â”œâ”€â”€ memory.index                # Memory FAISS index
â””â”€â”€ college_rag.log             # Logs
```

---

## ğŸ“ Summary

This chatbot uses **RAG (Retrieval-Augmented Generation)** to answer college-related questions:

1. **Retrieve** relevant info from database + memory
2. **Augment** the query with context
3. **Generate** natural language answer using AI

The system is fast (batched operations), persistent (saves indexes), and learns over time (memory system). Perfect for building educational assistants! ğŸš€